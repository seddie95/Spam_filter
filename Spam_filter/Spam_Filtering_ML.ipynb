{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_length</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>class</th>\n",
       "      <th>subject_stripped</th>\n",
       "      <th>text_stripped</th>\n",
       "      <th>subject_lemmatized</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>text_no_stops</th>\n",
       "      <th>subject_no_stops</th>\n",
       "      <th>topic_number</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9-208msg1.txt</td>\n",
       "      <td>a workshop on text , speech and dialog ( tsd '...</td>\n",
       "      <td>52</td>\n",
       "      <td>first announcement and call for papers a works...</td>\n",
       "      <td>6327</td>\n",
       "      <td>0</td>\n",
       "      <td>a workshop on text  speech and dialog  tsd  98</td>\n",
       "      <td>first announcement and call for papers a works...</td>\n",
       "      <td>a workshop on text   speech and dialog   tsd   98</td>\n",
       "      <td>first announcement and call for paper a worksh...</td>\n",
       "      <td>announcement paper workshop text    speech dia...</td>\n",
       "      <td>workshop text    speech dialog    tsd    98</td>\n",
       "      <td>2</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6-863msg1.txt</td>\n",
       "      <td>re : toc</td>\n",
       "      <td>9</td>\n",
       "      <td>dear colleague , i would like to send you the ...</td>\n",
       "      <td>1265</td>\n",
       "      <td>0</td>\n",
       "      <td>re  toc</td>\n",
       "      <td>dear colleague  i would like to send you the f...</td>\n",
       "      <td>re   toc</td>\n",
       "      <td>dear colleague   i would like to send -PRON- t...</td>\n",
       "      <td>dear colleague    like send -PRON- follow anno...</td>\n",
       "      <td>toc</td>\n",
       "      <td>1</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spmsga152.txt</td>\n",
       "      <td>free internet services &amp; unique shopping</td>\n",
       "      <td>41</td>\n",
       "      <td>here 's a great directory for free and interes...</td>\n",
       "      <td>553</td>\n",
       "      <td>1</td>\n",
       "      <td>free internet services  unique shopping</td>\n",
       "      <td>here s a great directory for free and interest...</td>\n",
       "      <td>free internet service   unique shopping</td>\n",
       "      <td>here s a great directory for free and interest...</td>\n",
       "      <td>s great directory free interesting internet si...</td>\n",
       "      <td>free internet service    unique shopping</td>\n",
       "      <td>3</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6-977msg1.txt</td>\n",
       "      <td>summary</td>\n",
       "      <td>8</td>\n",
       "      <td>dear all , i send you a summary of the answers...</td>\n",
       "      <td>6793</td>\n",
       "      <td>0</td>\n",
       "      <td>summary</td>\n",
       "      <td>dear all  i send you a summary of the answers ...</td>\n",
       "      <td>summary</td>\n",
       "      <td>dear all   i send -PRON- a summary of the answ...</td>\n",
       "      <td>dear    send -PRON- summary answer -PRON- quer...</td>\n",
       "      <td>summary</td>\n",
       "      <td>1</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8-1096msg1.txt</td>\n",
       "      <td>summary : vowel deletion between two like cons...</td>\n",
       "      <td>53</td>\n",
       "      <td>quite some time ago , i wrote requesting infor...</td>\n",
       "      <td>5793</td>\n",
       "      <td>0</td>\n",
       "      <td>summary  vowel deletion between two like conso...</td>\n",
       "      <td>quite some time ago  i wrote requesting inform...</td>\n",
       "      <td>summary   vowel deletion between two like cons...</td>\n",
       "      <td>quite some time ago   i write request informat...</td>\n",
       "      <td>time ago    write request information concern ...</td>\n",
       "      <td>summary    vowel deletion like consonant</td>\n",
       "      <td>1</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                                            subject  \\\n",
       "0   9-208msg1.txt  a workshop on text , speech and dialog ( tsd '...   \n",
       "1   6-863msg1.txt                                           re : toc   \n",
       "2   spmsga152.txt           free internet services & unique shopping   \n",
       "3   6-977msg1.txt                                            summary   \n",
       "4  8-1096msg1.txt  summary : vowel deletion between two like cons...   \n",
       "\n",
       "   subject_length                                               text  \\\n",
       "0              52  first announcement and call for papers a works...   \n",
       "1               9  dear colleague , i would like to send you the ...   \n",
       "2              41  here 's a great directory for free and interes...   \n",
       "3               8  dear all , i send you a summary of the answers...   \n",
       "4              53  quite some time ago , i wrote requesting infor...   \n",
       "\n",
       "   text_length  class                                   subject_stripped  \\\n",
       "0         6327      0     a workshop on text  speech and dialog  tsd  98   \n",
       "1         1265      0                                            re  toc   \n",
       "2          553      1            free internet services  unique shopping   \n",
       "3         6793      0                                            summary   \n",
       "4         5793      0  summary  vowel deletion between two like conso...   \n",
       "\n",
       "                                       text_stripped  \\\n",
       "0  first announcement and call for papers a works...   \n",
       "1  dear colleague  i would like to send you the f...   \n",
       "2  here s a great directory for free and interest...   \n",
       "3  dear all  i send you a summary of the answers ...   \n",
       "4  quite some time ago  i wrote requesting inform...   \n",
       "\n",
       "                                  subject_lemmatized  \\\n",
       "0  a workshop on text   speech and dialog   tsd   98   \n",
       "1                                           re   toc   \n",
       "2            free internet service   unique shopping   \n",
       "3                                            summary   \n",
       "4  summary   vowel deletion between two like cons...   \n",
       "\n",
       "                                     text_lemmatized  \\\n",
       "0  first announcement and call for paper a worksh...   \n",
       "1  dear colleague   i would like to send -PRON- t...   \n",
       "2  here s a great directory for free and interest...   \n",
       "3  dear all   i send -PRON- a summary of the answ...   \n",
       "4  quite some time ago   i write request informat...   \n",
       "\n",
       "                                       text_no_stops  \\\n",
       "0  announcement paper workshop text    speech dia...   \n",
       "1  dear colleague    like send -PRON- follow anno...   \n",
       "2  s great directory free interesting internet si...   \n",
       "3  dear    send -PRON- summary answer -PRON- quer...   \n",
       "4  time ago    write request information concern ...   \n",
       "\n",
       "                              subject_no_stops  topic_number     topic  \n",
       "0  workshop text    speech dialog    tsd    98             2   science  \n",
       "1                                          toc             1  language  \n",
       "2     free internet service    unique shopping             3     money  \n",
       "3                                      summary             1  language  \n",
       "4     summary    vowel deletion like consonant             1  language  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emails_cleaned.csv')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2809, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_length</th>\n",
       "      <th>text_length</th>\n",
       "      <th>subject_lemmatized</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>topic</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>6327</td>\n",
       "      <td>a workshop on text   speech and dialog   tsd   98</td>\n",
       "      <td>first announcement and call for paper a worksh...</td>\n",
       "      <td>science</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1265</td>\n",
       "      <td>re   toc</td>\n",
       "      <td>dear colleague   i would like to send -PRON- t...</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>553</td>\n",
       "      <td>free internet service   unique shopping</td>\n",
       "      <td>here s a great directory for free and interest...</td>\n",
       "      <td>money</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6793</td>\n",
       "      <td>summary</td>\n",
       "      <td>dear all   i send -PRON- a summary of the answ...</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>5793</td>\n",
       "      <td>summary   vowel deletion between two like cons...</td>\n",
       "      <td>quite some time ago   i write request informat...</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_length  text_length  \\\n",
       "0              52         6327   \n",
       "1               9         1265   \n",
       "2              41          553   \n",
       "3               8         6793   \n",
       "4              53         5793   \n",
       "\n",
       "                                  subject_lemmatized  \\\n",
       "0  a workshop on text   speech and dialog   tsd   98   \n",
       "1                                           re   toc   \n",
       "2            free internet service   unique shopping   \n",
       "3                                            summary   \n",
       "4  summary   vowel deletion between two like cons...   \n",
       "\n",
       "                                     text_lemmatized     topic  class  \n",
       "0  first announcement and call for paper a worksh...   science      0  \n",
       "1  dear colleague   i would like to send -PRON- t...  language      0  \n",
       "2  here s a great directory for free and interest...     money      1  \n",
       "3  dear all   i send -PRON- a summary of the answ...  language      0  \n",
       "4  quite some time ago   i write request informat...  language      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = df[['subject_length','text_length','subject_lemmatized','text_lemmatized','topic','class']]\n",
    "emails.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2809, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Encode Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_length</th>\n",
       "      <th>text_length</th>\n",
       "      <th>subject_lemmatized</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>class</th>\n",
       "      <th>topic_Academics</th>\n",
       "      <th>topic_administration</th>\n",
       "      <th>topic_language</th>\n",
       "      <th>topic_money</th>\n",
       "      <th>topic_science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>6327</td>\n",
       "      <td>a workshop on text   speech and dialog   tsd   98</td>\n",
       "      <td>first announcement and call for paper a worksh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1265</td>\n",
       "      <td>re   toc</td>\n",
       "      <td>dear colleague   i would like to send -PRON- t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>553</td>\n",
       "      <td>free internet service   unique shopping</td>\n",
       "      <td>here s a great directory for free and interest...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6793</td>\n",
       "      <td>summary</td>\n",
       "      <td>dear all   i send -PRON- a summary of the answ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>5793</td>\n",
       "      <td>summary   vowel deletion between two like cons...</td>\n",
       "      <td>quite some time ago   i write request informat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_length  text_length  \\\n",
       "0              52         6327   \n",
       "1               9         1265   \n",
       "2              41          553   \n",
       "3               8         6793   \n",
       "4              53         5793   \n",
       "\n",
       "                                  subject_lemmatized  \\\n",
       "0  a workshop on text   speech and dialog   tsd   98   \n",
       "1                                           re   toc   \n",
       "2            free internet service   unique shopping   \n",
       "3                                            summary   \n",
       "4  summary   vowel deletion between two like cons...   \n",
       "\n",
       "                                     text_lemmatized  class  topic_Academics  \\\n",
       "0  first announcement and call for paper a worksh...      0                0   \n",
       "1  dear colleague   i would like to send -PRON- t...      0                0   \n",
       "2  here s a great directory for free and interest...      1                0   \n",
       "3  dear all   i send -PRON- a summary of the answ...      0                0   \n",
       "4  quite some time ago   i write request informat...      0                0   \n",
       "\n",
       "   topic_administration  topic_language  topic_money  topic_science  \n",
       "0                     0               0            0              1  \n",
       "1                     0               1            0              0  \n",
       "2                     0               0            1              0  \n",
       "3                     0               1            0              0  \n",
       "4                     0               1            0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = pd.get_dummies(emails, columns=['topic'])\n",
    "encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded['subject_normalised'] = encoded['subject_length'].apply(\n",
    "    lambda x: (x-encoded['subject_length'].min())/(encoded['subject_length'].max() -encoded['subject_length'].min())\n",
    ")\n",
    "\n",
    "encoded['text_normalised'] = encoded['text_length'].apply(\n",
    "    lambda x: (x-encoded['text_length'].min())/(encoded['text_length'].max() -encoded['text_length'].min())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_length</th>\n",
       "      <th>text_length</th>\n",
       "      <th>subject_lemmatized</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>class</th>\n",
       "      <th>topic_Academics</th>\n",
       "      <th>topic_administration</th>\n",
       "      <th>topic_language</th>\n",
       "      <th>topic_money</th>\n",
       "      <th>topic_science</th>\n",
       "      <th>subject_normalised</th>\n",
       "      <th>text_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>6327</td>\n",
       "      <td>a workshop on text   speech and dialog   tsd   98</td>\n",
       "      <td>first announcement and call for paper a worksh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31250</td>\n",
       "      <td>0.220383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1265</td>\n",
       "      <td>re   toc</td>\n",
       "      <td>dear colleague   i would like to send -PRON- t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.043588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>553</td>\n",
       "      <td>free internet service   unique shopping</td>\n",
       "      <td>here s a great directory for free and interest...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24375</td>\n",
       "      <td>0.018720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6793</td>\n",
       "      <td>summary</td>\n",
       "      <td>dear all   i send -PRON- a summary of the answ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>0.236658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>5793</td>\n",
       "      <td>summary   vowel deletion between two like cons...</td>\n",
       "      <td>quite some time ago   i write request informat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.31875</td>\n",
       "      <td>0.201732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_length  text_length  \\\n",
       "0              52         6327   \n",
       "1               9         1265   \n",
       "2              41          553   \n",
       "3               8         6793   \n",
       "4              53         5793   \n",
       "\n",
       "                                  subject_lemmatized  \\\n",
       "0  a workshop on text   speech and dialog   tsd   98   \n",
       "1                                           re   toc   \n",
       "2            free internet service   unique shopping   \n",
       "3                                            summary   \n",
       "4  summary   vowel deletion between two like cons...   \n",
       "\n",
       "                                     text_lemmatized  class  topic_Academics  \\\n",
       "0  first announcement and call for paper a worksh...      0                0   \n",
       "1  dear colleague   i would like to send -PRON- t...      0                0   \n",
       "2  here s a great directory for free and interest...      1                0   \n",
       "3  dear all   i send -PRON- a summary of the answ...      0                0   \n",
       "4  quite some time ago   i write request informat...      0                0   \n",
       "\n",
       "   topic_administration  topic_language  topic_money  topic_science  \\\n",
       "0                     0               0            0              1   \n",
       "1                     0               1            0              0   \n",
       "2                     0               0            1              0   \n",
       "3                     0               1            0              0   \n",
       "4                     0               1            0              0   \n",
       "\n",
       "   subject_normalised  text_normalised  \n",
       "0             0.31250         0.220383  \n",
       "1             0.04375         0.043588  \n",
       "2             0.24375         0.018720  \n",
       "3             0.03750         0.236658  \n",
       "4             0.31875         0.201732  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test using Numeric Features only "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoded['class']\n",
    "encoded.drop(columns=['subject_lemmatized','text_lemmatized','class','subject_length','text_length'],inplace=True)\n",
    "X = encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_Academics</th>\n",
       "      <th>topic_administration</th>\n",
       "      <th>topic_language</th>\n",
       "      <th>topic_money</th>\n",
       "      <th>topic_science</th>\n",
       "      <th>subject_normalised</th>\n",
       "      <th>text_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31250</td>\n",
       "      <td>0.220383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.043588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24375</td>\n",
       "      <td>0.018720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>0.236658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.31875</td>\n",
       "      <td>0.201732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_Academics  topic_administration  topic_language  topic_money  \\\n",
       "0                0                     0               0            0   \n",
       "1                0                     0               1            0   \n",
       "2                0                     0               0            1   \n",
       "3                0                     0               1            0   \n",
       "4                0                     0               1            0   \n",
       "\n",
       "   topic_science  subject_normalised  text_normalised  \n",
       "0              1             0.31250         0.220383  \n",
       "1              0             0.04375         0.043588  \n",
       "2              0             0.24375         0.018720  \n",
       "3              0             0.03750         0.236658  \n",
       "4              0             0.31875         0.201732  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =log_reg.fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9012455516014235\n",
      "Balanced Accuracy: 0.9365541260109951\n",
      "Confusion Matrix:\n",
      "[[830 109]\n",
      " [  2 183]]\n",
      "CLassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94       939\n",
      "           1       0.63      0.99      0.77       185\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1124\n",
      "   macro avg       0.81      0.94      0.85      1124\n",
      "weighted avg       0.94      0.90      0.91      1124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {metrics.accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Balanced Accuracy: {metrics.balanced_accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{metrics.confusion_matrix(y_test,y_pred)}\")\n",
    "print(f\"CLassification Report:\\n{metrics.classification_report(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As would be expected the classifier predicts the majority class of ham with much greater precision only two False negative predictions. There are however a large number of False Negative predictions. This would suggest that there is not really a classifier bias towards the majority class which is further proved by the 0.99 recall for the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost = GradientBoostingClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8718861209964412\n",
      "Balanced Accuracy: 0.6845983363555249\n",
      "Confusion Matrix:\n",
      "[[905  34]\n",
      " [110  75]]\n",
      "CLassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       939\n",
      "           1       0.69      0.41      0.51       185\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      1124\n",
      "   macro avg       0.79      0.68      0.72      1124\n",
      "weighted avg       0.86      0.87      0.86      1124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred =grad_boost.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Balanced Accuracy: {metrics.balanced_accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{metrics.confusion_matrix(y_test,y_pred)}\")\n",
    "print(f\"CLassification Report:\\n{metrics.classification_report(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gradient boosting model when compared to the Logistic Regression model achieves a lower Accuracy and Balanced Accuracy. There appears to be a much greater classifier bias towards the majority class as the both the False Negative and True Negative preditcion have increased.\n",
    "\n",
    "On the otherhand the True positive class is predicted fewer times but with greater precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma='auto',random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9012455516014235\n",
      "Balanced Accuracy: 0.9365541260109951\n",
      "Confusion Matrix:\n",
      "[[830 109]\n",
      " [  2 183]]\n",
      "CLassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94       939\n",
      "           1       0.63      0.99      0.77       185\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1124\n",
      "   macro avg       0.81      0.94      0.85      1124\n",
      "weighted avg       0.94      0.90      0.91      1124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred =svm.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Balanced Accuracy: {metrics.balanced_accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{metrics.confusion_matrix(y_test,y_pred)}\")\n",
    "print(f\"CLassification Report:\\n{metrics.classification_report(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM is clearly biased towards the majority class with a huge jump in the number of False Negative and True Negative. The True Positive has also gretly droped with the recall of only 0.06. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin = LinearSVC(random_state=42,max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9012455516014235\n",
      "Balanced Accuracy: 0.9365541260109951\n",
      "Confusion Matrix:\n",
      "[[830 109]\n",
      " [  2 183]]\n",
      "CLassification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94       939\n",
      "           1       0.63      0.99      0.77       185\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1124\n",
      "   macro avg       0.81      0.94      0.85      1124\n",
      "weighted avg       0.94      0.90      0.91      1124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred =svm_lin.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Balanced Accuracy: {metrics.balanced_accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{metrics.confusion_matrix(y_test,y_pred)}\")\n",
    "print(f\"CLassification Report:\\n{metrics.classification_report(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Linear SVC is much less biased toward the majority class than the SVC model is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of models\n",
    "Overall the logistic regression model worked the best even with out any hyperparamter tuning. The SVC model was the least accurate at predicting Spam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "### Filter-based Feature Selection using Information GainÂ¶\n",
    "Information gain refers to the reduction of entropy calculated for a given dataset. By maximising the information gain it allows the data to be split into the most optimal datasets, thus reducing the entropy of the dataset, which in turn leads to a good quality classification.\n",
    "\n",
    "The filter-based feature selection of the dataset obtains the individual information gain associated with each of the features. The Information gain values will be used to rank the features based on the level of improvement to entropy. This method is useful for finding those features that will likely aid in the prediction process and those that may hinder it. The one drawback to this process is that it is classifier exclusive, so does not consider the individual classifiers biases towards certain features(Brownlee, 2019).\n",
    "\n",
    "Brownlee, J. (2019). Information Gain and Mutual Information for Machine Learning. [online] Machine Learning Mastery. Available at: https://machinelearningmastery.com/information-gain-and-mutual-information/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I-Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic_money</th>\n",
       "      <td>0.274075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_language</th>\n",
       "      <td>0.083048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_normalised</th>\n",
       "      <td>0.040962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_administration</th>\n",
       "      <td>0.038768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_science</th>\n",
       "      <td>0.026125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_normalised</th>\n",
       "      <td>0.014895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_Academics</th>\n",
       "      <td>0.006878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        I-Gain\n",
       "topic_money           0.274075\n",
       "topic_language        0.083048\n",
       "text_normalised       0.040962\n",
       "topic_administration  0.038768\n",
       "topic_science         0.026125\n",
       "subject_normalised    0.014895\n",
       "topic_Academics       0.006878"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = dict()\n",
    "\n",
    "i_scores = mutual_info_classif(X_train, y_train, random_state=42)\n",
    "\n",
    "for i, j in zip(X_train.columns, i_scores):\n",
    "    mi[i] = j\n",
    "\n",
    "df = pd.DataFrame.from_dict(mi, orient=\"index\", columns=[\"I-Gain\"])\n",
    "df.sort_values(by=[\"I-Gain\"], ascending=False, inplace=True)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the feature names in reverse order depending on infrmation gain\n",
    "i_gain = [x[1] for x in sorted([(v, k) for (k, v) in mi.items()], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I-Gain</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic_money</th>\n",
       "      <td>0.274075</td>\n",
       "      <td>0.93128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_language</th>\n",
       "      <td>0.083048</td>\n",
       "      <td>0.93128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_normalised</th>\n",
       "      <td>0.040962</td>\n",
       "      <td>0.93128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_administration</th>\n",
       "      <td>0.038768</td>\n",
       "      <td>0.93128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_science</th>\n",
       "      <td>0.026125</td>\n",
       "      <td>0.93128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_normalised</th>\n",
       "      <td>0.014895</td>\n",
       "      <td>0.93128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_Academics</th>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.93128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        I-Gain  Accuracy\n",
       "topic_money           0.274075   0.93128\n",
       "topic_language        0.083048   0.93128\n",
       "text_normalised       0.040962   0.93128\n",
       "topic_administration  0.038768   0.93128\n",
       "topic_science         0.026125   0.93128\n",
       "subject_normalised    0.014895   0.93128\n",
       "topic_Academics       0.006878   0.93128"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_ig test_ig split to\n",
    "X_train_ig, X_test_ig, y_train_ig, y_test_ig = train_test_split(\n",
    "    X_train, y_train, random_state=42\n",
    ")\n",
    "\n",
    "acc_scores = []\n",
    "for kk in range(1, X_train.shape[1] + 1):\n",
    "    FS_trans = SelectKBest(mutual_info_classif, k=kk).fit(X_train_ig, y_train_ig)\n",
    "    X_tR_new = FS_trans.transform(X_train_ig)\n",
    "    X_tS_new = FS_trans.transform(X_test_ig)\n",
    "    seg_NB = log_reg.fit(X_tR_new, y_train_ig)\n",
    "    y_dash = seg_NB.predict(X_tS_new)\n",
    "    acc = metrics.accuracy_score(y_test_ig, y_dash)\n",
    "    acc_scores.append(acc)\n",
    "\n",
    "df[\"Accuracy\"] = acc_scores\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 1, 0.9312796208530806\n",
      "Features: 2, 0.9312796208530806\n",
      "Features: 3, 0.9312796208530806\n",
      "Features: 4, 0.9312796208530806\n",
      "Features: 5, 0.9312796208530806\n",
      "Features: 6, 0.9312796208530806\n",
      "Features: 7, 0.9312796208530806\n"
     ]
    }
   ],
   "source": [
    "# Obtain the accuracies achived when adding each feature\n",
    "train = []\n",
    "accuracies = []\n",
    "best = 0\n",
    "best_idx = 0\n",
    "\n",
    "\n",
    "for i, feature in enumerate(i_gain):\n",
    "    train.append(feature)\n",
    "\n",
    "    X_tr_ig = X_train[train]\n",
    "\n",
    "    X_train_ig, X_test_ig, y_train_ig, y_test_ig = train_test_split(\n",
    "        X_tr_ig, y_train, random_state=42\n",
    "    )\n",
    "\n",
    "    y_pred = log_reg.fit(X_train_ig, y_train_ig).predict(X_test_ig)\n",
    "    ig_acc = metrics.accuracy_score(y_pred, y_test_ig)\n",
    "    accuracies.append(ig_acc)\n",
    "    print(f\"Features: {i+1}, {ig_acc}\")\n",
    "\n",
    "    if ig_acc >= best:\n",
    "        best = ig_acc\n",
    "        best_idx = i + 1\n",
    "\n",
    "\n",
    "best_features = train[:best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display the best features obtained using Information gain\n",
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing using  Single Text features\n",
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = pd.get_dummies(emails, columns=['topic'])\n",
    "encoded.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = emails['class']\n",
    "X = emails['text_lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {metrics.accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Balanced Accuracy: {metrics.balanced_accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{metrics.confusion_matrix(y_test,y_pred)}\")\n",
    "print(f\"CLassification Report:\\n{metrics.classification_report(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using The text feature as a sparse matrix the results are extremely good for both the ham and spamm emails with a total of 8 emails being incorrectly classified. The precision and recall for both the majority and minority class are very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing using Multiple Text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoded['class']\n",
    "X = encoded.loc[:, encoded.columns != 'class']\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FeatureUnion([\n",
    "                ('search_term_tfidf', \n",
    "                  Pipeline([('extract_field',\n",
    "                              FunctionTransformer(lambda x: x['subject_lemmatized'], \n",
    "                                                  validate=False)),\n",
    "                            ('tfidf', \n",
    "                              TfidfVectorizer())])),\n",
    "                ('product_title_tfidf', \n",
    "                  Pipeline([('extract_field', \n",
    "                              FunctionTransformer(lambda x: x['text_lemmatized'], \n",
    "                                                  validate=False)),\n",
    "                            ('tfidf', \n",
    "                              TfidfVectorizer())]))]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('transformer', transformer),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= text_clf.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Balanced Accuracy: {metrics.balanced_accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{metrics.confusion_matrix(y_test,y_pred)}\")\n",
    "print(f\"CLassification Report:\\n{metrics.classification_report(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When both text and subject are vectorized there is a small reduction in the accuracy of the model. This reduction would suggest that using the text alone is prefferable as it consists of a smaller matrix, which will allow for faster predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}